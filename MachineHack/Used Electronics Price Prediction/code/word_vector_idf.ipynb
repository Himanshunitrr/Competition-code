{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all imports and silence those pesky warninigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import FastTextKeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data and drop everything except text and concatenate train and test model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Info</th>\n",
       "      <th>Additional_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name0 name234 64gb space grey</td>\n",
       "      <td>1yesr old mobile number 999two905two99 bill c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phone 7 name42 name453 new condition box acces...</td>\n",
       "      <td>101004800 1010065900 7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name0 x 256gb leess used good condition</td>\n",
       "      <td>1010010000 seperate screen guard 3 back cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name0 6s plus 64 gb space grey</td>\n",
       "      <td>without 1010020100 id 1010010300 colour 10100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone 7 sealed pack brand new factory outet price</td>\n",
       "      <td>101008700 10100000 xs max 64 gb made 10100850...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model_Info  \\\n",
       "0                      name0 name234 64gb space grey   \n",
       "1  phone 7 name42 name453 new condition box acces...   \n",
       "2            name0 x 256gb leess used good condition   \n",
       "3                     name0 6s plus 64 gb space grey   \n",
       "4  phone 7 sealed pack brand new factory outet price   \n",
       "\n",
       "                              Additional_Description  \n",
       "0   1yesr old mobile number 999two905two99 bill c...  \n",
       "1                          101004800 1010065900 7000  \n",
       "2   1010010000 seperate screen guard 3 back cover...  \n",
       "3   without 1010020100 id 1010010300 colour 10100...  \n",
       "4   101008700 10100000 xs max 64 gb made 10100850...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Train_orig.csv\")\n",
    "df_test = pd.read_csv(\"Test_orig.csv\")\n",
    "\n",
    "df_train.drop([\"Locality\", \"City\", \"State\", \"Brand\", \"Price\"], axis=1, inplace=True)\n",
    "df_test.drop([\"Locality\", \"City\", \"State\", \"Brand\"], axis=1, inplace=True)\n",
    "\n",
    "df_train['Model_Info'] = df_train['Model_Info'].str.strip()\n",
    "df_test['Model_Info'] = df_test['Model_Info'].str.strip()\n",
    "text = list(df_train[\"Model_Info\"].values) + list(df_test[\"Model_Info\"].values)\n",
    "print(len(text))\n",
    "\n",
    "df_train.head()\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract IDF scores for only the model_info column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0758379341765374\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0, ngram_range=(1,1))#, token_pattern=r'\\S+')\n",
    "X = vectorizer.fit_transform(text)\n",
    "idf = vectorizer.idf_\n",
    "word_idf_vocab =  (dict(zip(vectorizer.get_feature_names(), idf)))\n",
    "\n",
    "print(word_idf_vocab[\"phone\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Word Vectors for both model_info and additional_description. This gives extra context to word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31009698\n",
      "0.017244127\n",
      "0.629973\n",
      "[ 0.35827553 -0.4996513  -0.8842419   0.33213007 -0.86428666  1.2041614\n",
      "  0.1875851   0.23505807  0.68442386  0.31361568  0.5453825  -1.3411456\n",
      " -0.16402972 -0.05248841 -0.16655952 -0.10903882  1.4380338   1.3334641\n",
      " -0.62738055 -0.22355151 -0.47950384  0.45036915 -0.03892191  0.31669244\n",
      "  0.36844802 -2.223459   -0.34856024  2.2016659  -1.8291218  -0.6372988\n",
      "  1.188055   -0.8722653   2.1782477   1.0628272  -0.14092915 -0.25043762\n",
      " -0.21599787 -2.407488    0.22487001  0.72106254  0.686195   -1.9380577\n",
      " -0.14663991  1.5226675  -0.8951958   1.6420304   1.2674861   1.6965528\n",
      "  0.7226418   0.01862778  1.5979679   1.4497461  -0.6487289  -1.1862932\n",
      "  0.07667118 -0.5463258  -0.95800656  0.08734243  1.8681282   0.66233826\n",
      " -0.77442473  0.18887177 -1.0500121  -0.9188245  -0.9409417   1.0163097\n",
      "  0.29525867  2.8721871  -1.1163372   1.273277    0.68531805 -1.8355119\n",
      " -0.98377216  0.1811434  -0.272642    1.1000841   0.8517749   1.4759264\n",
      " -0.49386713  0.8903005  -0.55747426 -0.5456473   0.74707156  0.05378807\n",
      "  0.2350626   1.1911365  -0.4595601  -1.2332623  -1.1561786   1.155544\n",
      "  0.7690907  -2.353204   -1.0045998   0.14010009 -2.0819175   1.241583\n",
      " -0.11625545 -1.917126    0.21393391  1.6877706 ]\n"
     ]
    }
   ],
   "source": [
    "all_text = [i.split() for i in text + list(df_train[\"Additional_Description\"].values) + list(df_test[\"Additional_Description\"].values)]\n",
    "\n",
    "model = Word2Vec(all_text, size=100, window=3, min_count=1, workers=4, seed=27)\n",
    "model.train(all_text ,total_examples=len(all_text), epochs=50)\n",
    "model.wv.save(\"word2vec_vectors1.bin\")\n",
    "\n",
    "print(model.similarity('iphone', 'apple'))\n",
    "print(model.similarity('iphone', 'honor'))\n",
    "print(model.similarity('iphone', 'phone'))\n",
    "print(model.wv['iphone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word vectors; Multiply them with their idf scores; Sum and save sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load(\"word2vec_vectors1.bin\")\n",
    "train_sents, test_sents = list(), list()\n",
    "\n",
    "# Dense vector representation for each sentence in train\n",
    "for sent in df_train['Model_Info'].values:\n",
    "    sent = sent.split()\n",
    "    # TF-IDF vectorizer removes all words less than 2 characters in length\n",
    "    # But word2vec trains everything. So that error needs to be accounted for\n",
    "    # That's done using the if statement inside list comprehension\n",
    "    tmp = [word_idf_vocab[word]*word_vectors[word] for word in sent if word in word_idf_vocab and word in word_vectors]\n",
    "    train_sents.append(np.sum(tmp, axis=0))\n",
    "fp = open(\"train_sents.bin\", \"wb\")\n",
    "pickle.dump(train_sents, fp)\n",
    "fp.close()\n",
    "\n",
    "# Dense vector representation for each sentence in test\n",
    "for sent in df_test['Model_Info'].values:\n",
    "    sent = sent.split()\n",
    "    tmp = [word_idf_vocab[word]*word_vectors[word] for word in sent if word in word_idf_vocab and word in word_vectors]\n",
    "    test_sents.append(np.sum(tmp, axis=0))\n",
    "fp = open(\"test_sents.bin\", \"wb\")\n",
    "pickle.dump(test_sents, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
